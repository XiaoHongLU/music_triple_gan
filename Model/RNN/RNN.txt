step 0, train : loss is 0.901492
step 0, validation : loss is 0.873984
step 100, train : loss is 0.693254
step 100, validation : loss is 0.693342
step 200, train : loss is 0.69323
step 200, validation : loss is 0.693309
step 300, train : loss is 0.693232
step 300, validation : loss is 0.693294
step 400, train : loss is 0.693231
step 400, validation : loss is 0.693259
step 500, train : loss is 0.693232
step 500, validation : loss is 0.693257
step 600, train : loss is 0.693232
step 600, validation : loss is 0.69326
step 700, train : loss is 0.693232
step 700, validation : loss is 0.693264
step 800, train : loss is 0.693232
step 800, validation : loss is 0.693265
step 900, train : loss is 0.693231
step 900, validation : loss is 0.69327
step 1000, train : loss is 0.69323
step 1000, validation : loss is 0.693275
step 1100, train : loss is 0.693229
step 1100, validation : loss is 0.693276
step 1200, train : loss is 0.693227
step 1200, validation : loss is 0.693275
step 1300, train : loss is 0.693226
step 1300, validation : loss is 0.693274
step 1400, train : loss is 0.693224
step 1400, validation : loss is 0.6933
step 1500, train : loss is 0.693223
step 1500, validation : loss is 0.693319
step 1600, train : loss is 0.693221
step 1600, validation : loss is 0.693327
step 1700, train : loss is 0.69322
step 1700, validation : loss is 0.693331
step 1800, train : loss is 0.693217
step 1800, validation : loss is 0.693338
step 1900, train : loss is 0.692984
step 1900, validation : loss is 0.693172
step 2000, train : loss is 0.692164
step 2000, validation : loss is 0.692987
step 2100, train : loss is 0.69162
step 2100, validation : loss is 0.693045
step 2200, train : loss is 0.691375
step 2200, validation : loss is 0.693138
step 2300, train : loss is 0.691213
step 2300, validation : loss is 0.693273
step 2400, train : loss is 0.691084
step 2400, validation : loss is 0.693346
step 2500, train : loss is 0.690983
step 2500, validation : loss is 0.693325
step 2600, train : loss is 0.690935
step 2600, validation : loss is 0.693325
step 2700, train : loss is 0.690876
step 2700, validation : loss is 0.693292
step 2800, train : loss is 0.690854
step 2800, validation : loss is 0.69329
step 2900, train : loss is 0.690841
step 2900, validation : loss is 0.693324
step 3000, train : loss is 0.690823
step 3000, validation : loss is 0.693407
step 3100, train : loss is 0.690802
step 3100, validation : loss is 0.693409
step 3200, train : loss is 0.690786
step 3200, validation : loss is 0.693414
step 3300, train : loss is 0.690781
step 3300, validation : loss is 0.693405
step 3400, train : loss is 0.690776
step 3400, validation : loss is 0.693406
step 3500, train : loss is 0.690771
step 3500, validation : loss is 0.693424
step 3600, train : loss is 0.690768
step 3600, validation : loss is 0.693395
step 3700, train : loss is 0.690767
step 3700, validation : loss is 0.693397
step 3800, train : loss is 0.690759
step 3800, validation : loss is 0.693384
step 3900, train : loss is 0.690757
step 3900, validation : loss is 0.693408
step 4000, train : loss is 0.690752
step 4000, validation : loss is 0.693401
step 4100, train : loss is 0.690748
step 4100, validation : loss is 0.693406
step 4200, train : loss is 0.690731
step 4200, validation : loss is 0.693364
step 4300, train : loss is 0.690719
step 4300, validation : loss is 0.693391
step 4400, train : loss is 0.690705
step 4400, validation : loss is 0.693375
step 4500, train : loss is 0.690695
step 4500, validation : loss is 0.693385
step 4600, train : loss is 0.690662
step 4600, validation : loss is 0.69351
step 4700, train : loss is 0.690551
step 4700, validation : loss is 0.693721
step 4800, train : loss is 0.69043
step 4800, validation : loss is 0.693782
step 4900, train : loss is 0.690279
step 4900, validation : loss is 0.69402
step 5000, train : loss is 0.690104
step 5000, validation : loss is 0.694069
step 5100, train : loss is 0.689835
step 5100, validation : loss is 0.694278
step 5200, train : loss is 0.689254
step 5200, validation : loss is 0.694624
step 5300, train : loss is 0.688772
step 5300, validation : loss is 0.694946
step 5400, train : loss is 0.688543
step 5400, validation : loss is 0.695268
step 5500, train : loss is 0.688235
step 5500, validation : loss is 0.695499
step 5600, train : loss is 0.688017
step 5600, validation : loss is 0.695692
step 5700, train : loss is 0.6878
step 5700, validation : loss is 0.695605
step 5800, train : loss is 0.687527
step 5800, validation : loss is 0.695867
step 5900, train : loss is 0.687216
step 5900, validation : loss is 0.69588
step 6000, train : loss is 0.686893
step 6000, validation : loss is 0.696157
step 6100, train : loss is 0.686594
step 6100, validation : loss is 0.696241
step 6200, train : loss is 0.686406
step 6200, validation : loss is 0.696291
step 6300, train : loss is 0.686081
step 6300, validation : loss is 0.696428
step 6400, train : loss is 0.685903
step 6400, validation : loss is 0.696638
step 6500, train : loss is 0.685789
step 6500, validation : loss is 0.696724
step 6600, train : loss is 0.685632
step 6600, validation : loss is 0.696893
step 6700, train : loss is 0.685678
step 6700, validation : loss is 0.696975
step 6800, train : loss is 0.68548
step 6800, validation : loss is 0.697052
step 6900, train : loss is 0.685414
step 6900, validation : loss is 0.697077
step 7000, train : loss is 0.685334
step 7000, validation : loss is 0.697088
step 7100, train : loss is 0.686304
step 7100, validation : loss is 0.697123
step 7200, train : loss is 0.68527
step 7200, validation : loss is 0.697147
step 7300, train : loss is 0.685206
step 7300, validation : loss is 0.697331
step 7400, train : loss is 0.685138
step 7400, validation : loss is 0.697318
step 7500, train : loss is 0.68507
step 7500, validation : loss is 0.697358
step 7600, train : loss is 0.685032
step 7600, validation : loss is 0.697463
step 7700, train : loss is 0.685121
step 7700, validation : loss is 0.697392
step 7800, train : loss is 0.68521
step 7800, validation : loss is 0.697384
step 7900, train : loss is 0.685088
step 7900, validation : loss is 0.697474
step 8000, train : loss is 0.68495
step 8000, validation : loss is 0.697245
step 8100, train : loss is 0.684941
step 8100, validation : loss is 0.69726
step 8200, train : loss is 0.68487
step 8200, validation : loss is 0.697242
step 8300, train : loss is 0.684837
step 8300, validation : loss is 0.697332
step 8400, train : loss is 0.684782
step 8400, validation : loss is 0.697344
step 8500, train : loss is 0.684751
step 8500, validation : loss is 0.697395
step 8600, train : loss is 0.68469
step 8600, validation : loss is 0.697543
step 8700, train : loss is 0.684651
step 8700, validation : loss is 0.697696
step 8800, train : loss is 0.684605
step 8800, validation : loss is 0.697813
step 8900, train : loss is 0.684557
step 8900, validation : loss is 0.697849
step 9000, train : loss is 0.684572
step 9000, validation : loss is 0.697806
step 9100, train : loss is 0.684469
step 9100, validation : loss is 0.697761
step 9200, train : loss is 0.684423
step 9200, validation : loss is 0.697786
step 9300, train : loss is 0.68439
step 9300, validation : loss is 0.697779
step 9400, train : loss is 0.684358
step 9400, validation : loss is 0.697732
step 9500, train : loss is 0.684552
step 9500, validation : loss is 0.697535
step 9600, train : loss is 0.684405
step 9600, validation : loss is 0.697636
step 9700, train : loss is 0.684625
step 9700, validation : loss is 0.697553
step 9800, train : loss is 0.68436
step 9800, validation : loss is 0.69782
step 9900, train : loss is 0.684144
step 9900, validation : loss is 0.697836
test dataset : loss is 0.697286
